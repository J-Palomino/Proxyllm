model_list:
  # Ollama models via hab (Tailscale)
  - model_name: llama3
    litellm_params:
      model: ollama/llama3
      api_base: http://100.75.148.4:11434  # hab via Tailscale
    model_info:
      id: "hab-llama3"

  - model_name: llama2
    litellm_params:
      model: ollama/llama2
      api_base: http://100.75.148.4:11434  # hab via Tailscale
    model_info:
      id: "hab-llama2"

  - model_name: mistral
    litellm_params:
      model: ollama/mistral
      api_base: http://100.75.148.4:11434  # hab via Tailscale
    model_info:
      id: "hab-mistral"

  # Wildcard support for any Ollama model on hab
  - model_name: "ollama/*"
    litellm_params:
      model: "ollama/*"
      api_base: http://100.75.148.4:11434  # hab via Tailscale

litellm_settings:
  drop_params: True
  num_retries: 3
  request_timeout: 600
  telemetry: False

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  store_model_in_db: False
  database_url: os.environ/DATABASE_URL
  database_connection_pool_limit: 20
  database_connection_timeout: 60

  # IP Whitelist - Add your approved client IPs here
  # allowed_ips:
  #   - "1.2.3.4"      # Example client IP 1
  #   - "5.6.7.8"      # Example client IP 2
  #   - "10.0.0.0/24"  # Example IP range
